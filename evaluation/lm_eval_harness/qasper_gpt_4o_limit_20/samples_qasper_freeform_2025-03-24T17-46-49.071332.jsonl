{"doc_id": 0, "doc": {"title": "Cross-lingual Pre-training Based Transfer for Zero-shot Neural Machine Translation", "abstract": "Transfer learning between different language pairs has shown its effectiveness for Neural Machine Translation (NMT) in low-resource scenario. However, existing transfer methods involving a common target language are far from success in the extreme scenario of zero-shot translation, due to the language space mismatch problem between transferor (the parent model) and transferee (the child model) on the source side. To address this challenge, we propose an effective transfer learning approach based on cross-lingual pre-training. Our key idea is to make all source languages share the same feature space and thus enable a smooth transition for zero-shot translation. To this end, we introduce one monolingual pre-training method and two bilingual pre-training methods to obtain a universal encoder for different languages. Once the universal encoder is constructed, the parent model built on such encoder is trained with large-scale annotated data and then directly applied in zero-shot translation scenario. Experiments on two public datasets show that our approach significantly outperforms strong pivot-based baseline and various multilingual NMT approaches.", "question": "what language pairs are explored?", "answer": "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru", "answer_type": "free form answer"}, "target": "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Cross-lingual Pre-training Based Transfer for Zero-shot Neural Machine Translation\\nABSTRACT: Transfer learning between different language pairs has shown its effectiveness for Neural Machine Translation (NMT) in low-resource scenario. However, existing transfer methods involving a common target language are far from success in the extreme scenario of zero-shot translation, due to the language space mismatch problem between transferor (the parent model) and transferee (the child model) on the source side. To address this challenge, we propose an effective transfer learning approach based on cross-lingual pre-training. Our key idea is to make all source languages share the same feature space and thus enable a smooth transition for zero-shot translation. To this end, we introduce one monolingual pre-training method and two bilingual pre-training methods to obtain a universal encoder for different languages. Once the universal encoder is constructed, the parent model built on such encoder is trained with large-scale annotated data and then directly applied in zero-shot translation scenario. Experiments on two public datasets show that our approach significantly outperforms strong pivot-based baseline and various multilingual NMT approaches.\\n\\nQ: what language pairs are explored?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The abstract does not specify the exact language pairs explored in the study. To determine the language pairs used in the experiments, one would need to refer to the full paper where the authors typically provide detailed information about the datasets and language pairs involved in their experiments."]], "filtered_resps": ["The abstract does not specify the exact language pairs explored in the study. To determine the language pairs used in the experiments, one would need to refer to the full paper where the authors typically provide detailed information about the datasets and language pairs involved in their experiments."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "1fe7e19c0bb7f1deadc4e48c2374bb24845ac76aa7c717f7d4f9997fec9fed5a", "prompt_hash": "320b1cec06acc125f87341b9b567c183a89cd346a65062af3329ea3d6c1a2a88", "target_hash": "60bfe9f2769c8b49d179c64003a6ed2e4e2232f851d09372c9ae7509a9d0aef4", "f1_abstractive": 0}
{"doc_id": 1, "doc": {"title": "Identifying Dogmatism in Social Media: Signals and Models", "abstract": "We explore linguistic and behavioral features of dogmatism in social media and construct statistical models that can identify dogmatic comments. Our model is based on a corpus of Reddit posts, collected across a diverse set of conversational topics and annotated via paid crowdsourcing. We operationalize key aspects of dogmatism described by existing psychology theories (such as over-confidence), finding they have predictive power. We also find evidence for new signals of dogmatism, such as the tendency of dogmatic posts to refrain from signaling cognitive processes. When we use our predictive model to analyze millions of other Reddit posts, we find evidence that suggests dogmatism is a deeper personality trait, present for dogmatic users across many different domains, and that users who engage on dogmatic comments tend to show increases in dogmatic posts themselves.", "question": "what are the topics pulled from Reddit?", "answer": "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit", "answer_type": "free form answer"}, "target": "training data has posts from politics, business, science and other popular topics; the trained model is applied to millions of unannotated posts on all of Reddit", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Identifying Dogmatism in Social Media: Signals and Models\\nABSTRACT: We explore linguistic and behavioral features of dogmatism in social media and construct statistical models that can identify dogmatic comments. Our model is based on a corpus of Reddit posts, collected across a diverse set of conversational topics and annotated via paid crowdsourcing. We operationalize key aspects of dogmatism described by existing psychology theories (such as over-confidence), finding they have predictive power. We also find evidence for new signals of dogmatism, such as the tendency of dogmatic posts to refrain from signaling cognitive processes. When we use our predictive model to analyze millions of other Reddit posts, we find evidence that suggests dogmatism is a deeper personality trait, present for dogmatic users across many different domains, and that users who engage on dogmatic comments tend to show increases in dogmatic posts themselves.\\n\\nQ: what are the topics pulled from Reddit?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The abstract does not specify the exact topics pulled from Reddit for the study. It mentions that the corpus of Reddit posts was collected across a diverse set of conversational topics, but it does not provide details on what those specific topics are. To find out the exact topics, one would need to refer to the full paper or supplementary materials where the methodology and data collection process are described in detail."]], "filtered_resps": ["The abstract does not specify the exact topics pulled from Reddit for the study. It mentions that the corpus of Reddit posts was collected across a diverse set of conversational topics, but it does not provide details on what those specific topics are. To find out the exact topics, one would need to refer to the full paper or supplementary materials where the methodology and data collection process are described in detail."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "5684f4b030c1e44ccd19d8812c81b24f72db9bfcd277ce5952afada83c6004d8", "prompt_hash": "9c4e129d73676479ad10fb709575922e84b79ab01db4dc1df69fd057c40624ee", "target_hash": "532b4847f560ca61d455ccd77d3ceeb109087faed34f923a6745172b11589583", "f1_abstractive": 0.2247191011235955}
{"doc_id": 2, "doc": {"title": "Adversarial Learning for Chinese NER from Crowd Annotations", "abstract": "To quickly obtain new labeled data, we can choose crowdsourcing as an alternative way at lower cost in a short time. But as an exchange, crowd annotations from non-experts may be of lower quality than those from experts. In this paper, we propose an approach to performing crowd annotation learning for Chinese Named Entity Recognition (NER) to make full use of the noisy sequence labels from multiple annotators. Inspired by adversarial learning, our approach uses a common Bi-LSTM and a private Bi-LSTM for representing annotator-generic and -specific information. The annotator-generic information is the common knowledge for entities easily mastered by the crowd. Finally, we build our Chinese NE tagger based on the LSTM-CRF model. In our experiments, we create two data sets for Chinese NER tasks from two domains. The experimental results show that our system achieves better scores than strong baseline systems.", "question": "What accuracy does the proposed system achieve?", "answer": "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ", "answer_type": "free form answer"}, "target": "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Adversarial Learning for Chinese NER from Crowd Annotations\\nABSTRACT: To quickly obtain new labeled data, we can choose crowdsourcing as an alternative way at lower cost in a short time. But as an exchange, crowd annotations from non-experts may be of lower quality than those from experts. In this paper, we propose an approach to performing crowd annotation learning for Chinese Named Entity Recognition (NER) to make full use of the noisy sequence labels from multiple annotators. Inspired by adversarial learning, our approach uses a common Bi-LSTM and a private Bi-LSTM for representing annotator-generic and -specific information. The annotator-generic information is the common knowledge for entities easily mastered by the crowd. Finally, we build our Chinese NE tagger based on the LSTM-CRF model. In our experiments, we create two data sets for Chinese NER tasks from two domains. The experimental results show that our system achieves better scores than strong baseline systems.\\n\\nQ: What accuracy does the proposed system achieve?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The abstract does not provide specific accuracy figures for the proposed system. To find the exact accuracy achieved by the system, you would need to refer to the full paper where the experimental results are discussed in detail."]], "filtered_resps": ["The abstract does not provide specific accuracy figures for the proposed system. To find the exact accuracy achieved by the system, you would need to refer to the full paper where the experimental results are discussed in detail."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "ac892b5442ad28502b2cabab6935f6e5eddc5fb473b567d91bd55e691dd07521", "prompt_hash": "2eeff549db1ffc7d223a6ab4459f492bb4f608a9e13a48ae7528b9c5aaa6b43f", "target_hash": "b4d0ccf4d89ee7da4865456e0c5cf12c04731e21a3ce548dabd5034f7286d34e", "f1_abstractive": 0}
{"doc_id": 3, "doc": {"title": "Adversarial Learning for Chinese NER from Crowd Annotations", "abstract": "To quickly obtain new labeled data, we can choose crowdsourcing as an alternative way at lower cost in a short time. But as an exchange, crowd annotations from non-experts may be of lower quality than those from experts. In this paper, we propose an approach to performing crowd annotation learning for Chinese Named Entity Recognition (NER) to make full use of the noisy sequence labels from multiple annotators. Inspired by adversarial learning, our approach uses a common Bi-LSTM and a private Bi-LSTM for representing annotator-generic and -specific information. The annotator-generic information is the common knowledge for entities easily mastered by the crowd. Finally, we build our Chinese NE tagger based on the LSTM-CRF model. In our experiments, we create two data sets for Chinese NER tasks from two domains. The experimental results show that our system achieves better scores than strong baseline systems.", "question": "What accuracy does the proposed system achieve?", "answer": "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)", "answer_type": "free form answer"}, "target": "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Adversarial Learning for Chinese NER from Crowd Annotations\\nABSTRACT: To quickly obtain new labeled data, we can choose crowdsourcing as an alternative way at lower cost in a short time. But as an exchange, crowd annotations from non-experts may be of lower quality than those from experts. In this paper, we propose an approach to performing crowd annotation learning for Chinese Named Entity Recognition (NER) to make full use of the noisy sequence labels from multiple annotators. Inspired by adversarial learning, our approach uses a common Bi-LSTM and a private Bi-LSTM for representing annotator-generic and -specific information. The annotator-generic information is the common knowledge for entities easily mastered by the crowd. Finally, we build our Chinese NE tagger based on the LSTM-CRF model. In our experiments, we create two data sets for Chinese NER tasks from two domains. The experimental results show that our system achieves better scores than strong baseline systems.\\n\\nQ: What accuracy does the proposed system achieve?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The abstract does not provide specific accuracy figures for the proposed system. To find the exact accuracy achieved by the system, you would need to refer to the full paper where the experimental results are discussed in detail."]], "filtered_resps": ["The abstract does not provide specific accuracy figures for the proposed system. To find the exact accuracy achieved by the system, you would need to refer to the full paper where the experimental results are discussed in detail."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "b45ed01e600419e568ed5e8811fb510ce1e82d1bd5f42ff7b298195234659319", "prompt_hash": "2eeff549db1ffc7d223a6ab4459f492bb4f608a9e13a48ae7528b9c5aaa6b43f", "target_hash": "e2b51e7eef2f8f09a4b17630d15e6e097e7c49dcf3536c6ffe37fb9611f54fd2", "f1_abstractive": 0}
{"doc_id": 4, "doc": {"title": "Adversarial Learning for Chinese NER from Crowd Annotations", "abstract": "To quickly obtain new labeled data, we can choose crowdsourcing as an alternative way at lower cost in a short time. But as an exchange, crowd annotations from non-experts may be of lower quality than those from experts. In this paper, we propose an approach to performing crowd annotation learning for Chinese Named Entity Recognition (NER) to make full use of the noisy sequence labels from multiple annotators. Inspired by adversarial learning, our approach uses a common Bi-LSTM and a private Bi-LSTM for representing annotator-generic and -specific information. The annotator-generic information is the common knowledge for entities easily mastered by the crowd. Finally, we build our Chinese NE tagger based on the LSTM-CRF model. In our experiments, we create two data sets for Chinese NER tasks from two domains. The experimental results show that our system achieves better scores than strong baseline systems.", "question": "What crowdsourcing platform is used?", "answer": "They did not use any platform, instead they hired undergraduate students to do the annotation.", "answer_type": "free form answer"}, "target": "They did not use any platform, instead they hired undergraduate students to do the annotation.", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Adversarial Learning for Chinese NER from Crowd Annotations\\nABSTRACT: To quickly obtain new labeled data, we can choose crowdsourcing as an alternative way at lower cost in a short time. But as an exchange, crowd annotations from non-experts may be of lower quality than those from experts. In this paper, we propose an approach to performing crowd annotation learning for Chinese Named Entity Recognition (NER) to make full use of the noisy sequence labels from multiple annotators. Inspired by adversarial learning, our approach uses a common Bi-LSTM and a private Bi-LSTM for representing annotator-generic and -specific information. The annotator-generic information is the common knowledge for entities easily mastered by the crowd. Finally, we build our Chinese NE tagger based on the LSTM-CRF model. In our experiments, we create two data sets for Chinese NER tasks from two domains. The experimental results show that our system achieves better scores than strong baseline systems.\\n\\nQ: What crowdsourcing platform is used?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The document does not specify which crowdsourcing platform is used for obtaining the crowd annotations."]], "filtered_resps": ["The document does not specify which crowdsourcing platform is used for obtaining the crowd annotations."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "47e3de2807e7a4637074ff41c9b7dd242fd900042b7b4b5ef5e20240916fa4a4", "prompt_hash": "426f7f590c8c5563c1eb7f72b86483771d5c964a997680482ef187635c63cb14", "target_hash": "66b61f20a3365e408eb403d722ca9c6fd53cce80f4549748893336156fb285a0", "f1_abstractive": 0.14814814814814817}
{"doc_id": 5, "doc": {"title": "Addressing word-order Divergence in Multilingual Neural Machine Translation for extremely Low Resource Languages", "abstract": "Transfer learning approaches for Neural Machine Translation (NMT) train a NMT model on the assisting-target language pair (parent model) which is later fine-tuned for the source-target language pair of interest (child model), with the target language being the same. In many cases, the assisting language has a different word order from the source language. We show that divergent word order adversely limits the benefits from transfer learning when little to no parallel corpus between the source and target language is available. To bridge this divergence, We propose to pre-order the assisting language sentence to match the word order of the source language and train the parent model. Our experiments on many language pairs show that bridging the word order gap leads to significant improvement in the translation quality.", "question": "On how many language pairs do they show that preordering assisting language sentences helps translation quality?", "answer": "5", "answer_type": "free form answer"}, "target": "5", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Addressing word-order Divergence in Multilingual Neural Machine Translation for extremely Low Resource Languages\\nABSTRACT: Transfer learning approaches for Neural Machine Translation (NMT) train a NMT model on the assisting-target language pair (parent model) which is later fine-tuned for the source-target language pair of interest (child model), with the target language being the same. In many cases, the assisting language has a different word order from the source language. We show that divergent word order adversely limits the benefits from transfer learning when little to no parallel corpus between the source and target language is available. To bridge this divergence, We propose to pre-order the assisting language sentence to match the word order of the source language and train the parent model. Our experiments on many language pairs show that bridging the word order gap leads to significant improvement in the translation quality.\\n\\nQ: On how many language pairs do they show that preordering assisting language sentences helps translation quality?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The abstract does not specify the exact number of language pairs on which the experiments were conducted. It only mentions that experiments were conducted on \"many language pairs\" to show that bridging the word order gap leads to significant improvement in translation quality."]], "filtered_resps": ["The abstract does not specify the exact number of language pairs on which the experiments were conducted. It only mentions that experiments were conducted on \"many language pairs\" to show that bridging the word order gap leads to significant improvement in translation quality."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "7a9f62d79ca2b1548ecca58152b7648b89836814bd9d4d25d138d2cf32dc605e", "prompt_hash": "e7a52520f66f36ad815e95ef7fa11b42cc0cb31121d5d250becc20a188de44e5", "target_hash": "ef2d127de37b942baad06145e54b0c619a1f22327b2ebbcfbec78f5564afe39d", "f1_abstractive": 0}
{"doc_id": 6, "doc": {"title": "A Corpus for Automatic Readability Assessment and Text Simplification of German", "abstract": "In this paper, we present a corpus for use in automatic readability assessment and automatic text simplification of German. The corpus is compiled from web sources and consists of approximately 211,000 sentences. As a novel contribution, it contains information on text structure, typography, and images, which can be exploited as part of machine learning approaches to readability assessment and text simplification. The focus of this publication is on representing such information as an extension to an existing corpus standard.", "question": "Which information about text structure is included in the corpus?", "answer": "paragraph, lines, textspan element (paragraph segmentation, line segmentation, Information on physical page segmentation(for PDF only))", "answer_type": "free form answer"}, "target": "paragraph, lines, textspan element (paragraph segmentation, line segmentation, Information on physical page segmentation(for PDF only))", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: A Corpus for Automatic Readability Assessment and Text Simplification of German\\nABSTRACT: In this paper, we present a corpus for use in automatic readability assessment and automatic text simplification of German. The corpus is compiled from web sources and consists of approximately 211,000 sentences. As a novel contribution, it contains information on text structure, typography, and images, which can be exploited as part of machine learning approaches to readability assessment and text simplification. The focus of this publication is on representing such information as an extension to an existing corpus standard.\\n\\nQ: Which information about text structure is included in the corpus?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The corpus includes information on text structure, typography, and images. This information can be used as part of machine learning approaches to readability assessment and text simplification. The specific details about text structure that are included in the corpus are not explicitly mentioned in the abstract, but it implies that such structural information is represented as an extension to an existing corpus standard."]], "filtered_resps": ["The corpus includes information on text structure, typography, and images. This information can be used as part of machine learning approaches to readability assessment and text simplification. The specific details about text structure that are included in the corpus are not explicitly mentioned in the abstract, but it implies that such structural information is represented as an extension to an existing corpus standard."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "9ae72a47ee2d78664c05bb3445352be15d56f5d9b18448e3e6ac722e482c3988", "prompt_hash": "cd2c649360bb7322a5505820bd9295f18edd0d9e2afc625fdd19d85bbc6429fd", "target_hash": "13c2d3faa3de309f2799ad33960e71e8c9ad4a514e658427224c95d8eacbea08", "f1_abstractive": 0.05555555555555556}
{"doc_id": 7, "doc": {"title": "How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings", "abstract": "Replacing static word embeddings with contextualized word representations has yielded significant improvements on many NLP tasks. However, just how contextual are the contextualized representations produced by models such as ELMo and BERT? Are there infinitely many context-specific representations for each word, or are words essentially assigned one of a finite number of word-sense representations? For one, we find that the contextualized representations of all words are not isotropic in any layer of the contextualizing model. While representations of the same word in different contexts still have a greater cosine similarity than those of two different words, this self-similarity is much lower in upper layers. This suggests that upper layers of contextualizing models produce more context-specific representations, much like how upper layers of LSTMs produce more task-specific representations. In all layers of ELMo, BERT, and GPT-2, on average, less than 5% of the variance in a word's contextualized representations can be explained by a static embedding for that word, providing some justification for the success of contextualized representations.", "question": "What experiments are proposed to test that upper layers produce context-specific embeddings?", "answer": "They measure self-similarity, intra-sentence similarity and maximum explainable variance of the embeddings in the upper layers.", "answer_type": "free form answer"}, "target": "They measure self-similarity, intra-sentence similarity and maximum explainable variance of the embeddings in the upper layers.", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings\\nABSTRACT: Replacing static word embeddings with contextualized word representations has yielded significant improvements on many NLP tasks. However, just how contextual are the contextualized representations produced by models such as ELMo and BERT? Are there infinitely many context-specific representations for each word, or are words essentially assigned one of a finite number of word-sense representations? For one, we find that the contextualized representations of all words are not isotropic in any layer of the contextualizing model. While representations of the same word in different contexts still have a greater cosine similarity than those of two different words, this self-similarity is much lower in upper layers. This suggests that upper layers of contextualizing models produce more context-specific representations, much like how upper layers of LSTMs produce more task-specific representations. In all layers of ELMo, BERT, and GPT-2, on average, less than 5% of the variance in a word's contextualized representations can be explained by a static embedding for that word, providing some justification for the success of contextualized representations.\\n\\nQ: What experiments are proposed to test that upper layers produce context-specific embeddings?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The paper proposes experiments that involve analyzing the cosine similarity of contextualized word representations across different layers of models like ELMo, BERT, and GPT-2. Specifically, the experiments aim to compare the self-similarity of the same word in different contexts across various layers. The hypothesis is that if upper layers produce more context-specific embeddings, the cosine similarity of the same word in different contexts should be lower in these layers compared to lower layers. This would indicate that the representations are becoming more context-specific as they move through the layers of the model. Additionally, the paper suggests examining the variance in a word's contextualized representations that can be explained by a static embedding, with the expectation that this variance should decrease in upper layers, further supporting the context-specific nature of these embeddings."]], "filtered_resps": ["The paper proposes experiments that involve analyzing the cosine similarity of contextualized word representations across different layers of models like ELMo, BERT, and GPT-2. Specifically, the experiments aim to compare the self-similarity of the same word in different contexts across various layers. The hypothesis is that if upper layers produce more context-specific embeddings, the cosine similarity of the same word in different contexts should be lower in these layers compared to lower layers. This would indicate that the representations are becoming more context-specific as they move through the layers of the model. Additionally, the paper suggests examining the variance in a word's contextualized representations that can be explained by a static embedding, with the expectation that this variance should decrease in upper layers, further supporting the context-specific nature of these embeddings."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "cad36c8a558045589e0d8539228e023c522546514fb1f5fa4a8a5b0da508bcaf", "prompt_hash": "081a7ae6396bce1c47882427a8b4fd9664c4edfb3be6e957ad7d333e6858f1b1", "target_hash": "b2d4dca65073805f8c0610c4d2c1ba1be6a0b075299eb7554909ea24e8d1c0dd", "f1_abstractive": 0.15625}
{"doc_id": 8, "doc": {"title": "How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings", "abstract": "Replacing static word embeddings with contextualized word representations has yielded significant improvements on many NLP tasks. However, just how contextual are the contextualized representations produced by models such as ELMo and BERT? Are there infinitely many context-specific representations for each word, or are words essentially assigned one of a finite number of word-sense representations? For one, we find that the contextualized representations of all words are not isotropic in any layer of the contextualizing model. While representations of the same word in different contexts still have a greater cosine similarity than those of two different words, this self-similarity is much lower in upper layers. This suggests that upper layers of contextualizing models produce more context-specific representations, much like how upper layers of LSTMs produce more task-specific representations. In all layers of ELMo, BERT, and GPT-2, on average, less than 5% of the variance in a word's contextualized representations can be explained by a static embedding for that word, providing some justification for the success of contextualized representations.", "question": "What experiments are proposed to test that upper layers produce context-specific embeddings?", "answer": "They plot the average cosine similarity between uniformly random words increases exponentially from layers 8 through 12.  \nThey plot the average self-similarity of uniformly randomly sampled words in each layer of BERT, ELMo, and GPT-2 and shown that the higher layer produces more context-specific embeddings.\nThey plot that word representations in a sentence become more context-specific in upper layers, they drift away from one another.", "answer_type": "free form answer"}, "target": "They plot the average cosine similarity between uniformly random words increases exponentially from layers 8 through 12.  \nThey plot the average self-similarity of uniformly randomly sampled words in each layer of BERT, ELMo, and GPT-2 and shown that the higher layer produces more context-specific embeddings.\nThey plot that word representations in a sentence become more context-specific in upper layers, they drift away from one another.", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings\\nABSTRACT: Replacing static word embeddings with contextualized word representations has yielded significant improvements on many NLP tasks. However, just how contextual are the contextualized representations produced by models such as ELMo and BERT? Are there infinitely many context-specific representations for each word, or are words essentially assigned one of a finite number of word-sense representations? For one, we find that the contextualized representations of all words are not isotropic in any layer of the contextualizing model. While representations of the same word in different contexts still have a greater cosine similarity than those of two different words, this self-similarity is much lower in upper layers. This suggests that upper layers of contextualizing models produce more context-specific representations, much like how upper layers of LSTMs produce more task-specific representations. In all layers of ELMo, BERT, and GPT-2, on average, less than 5% of the variance in a word's contextualized representations can be explained by a static embedding for that word, providing some justification for the success of contextualized representations.\\n\\nQ: What experiments are proposed to test that upper layers produce context-specific embeddings?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The paper proposes experiments that involve analyzing the cosine similarity of contextualized word representations across different layers of models like ELMo, BERT, and GPT-2. Specifically, the experiments aim to compare the self-similarity of the same word in different contexts across various layers. The hypothesis is that if upper layers produce more context-specific embeddings, the cosine similarity of the same word in different contexts should be lower in these layers compared to lower layers. This would indicate that the representations are becoming more context-specific as they move through the layers of the model. Additionally, the paper suggests examining the variance in a word's contextualized representations that can be explained by a static embedding, with the expectation that this variance should decrease in upper layers, further supporting the context-specific nature of these embeddings."]], "filtered_resps": ["The paper proposes experiments that involve analyzing the cosine similarity of contextualized word representations across different layers of models like ELMo, BERT, and GPT-2. Specifically, the experiments aim to compare the self-similarity of the same word in different contexts across various layers. The hypothesis is that if upper layers produce more context-specific embeddings, the cosine similarity of the same word in different contexts should be lower in these layers compared to lower layers. This would indicate that the representations are becoming more context-specific as they move through the layers of the model. Additionally, the paper suggests examining the variance in a word's contextualized representations that can be explained by a static embedding, with the expectation that this variance should decrease in upper layers, further supporting the context-specific nature of these embeddings."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "cc097f0ae2daf014cffa6a54b8ae9f3f414e81af10b125a2d49b7a420a81eccb", "prompt_hash": "081a7ae6396bce1c47882427a8b4fd9664c4edfb3be6e957ad7d333e6858f1b1", "target_hash": "e698a3aeb4d4a5861db6fb44bcf8c98425b92b6c79ed7611a8de3fc84aab66f1", "f1_abstractive": 0.30857142857142855}
{"doc_id": 9, "doc": {"title": "How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings", "abstract": "Replacing static word embeddings with contextualized word representations has yielded significant improvements on many NLP tasks. However, just how contextual are the contextualized representations produced by models such as ELMo and BERT? Are there infinitely many context-specific representations for each word, or are words essentially assigned one of a finite number of word-sense representations? For one, we find that the contextualized representations of all words are not isotropic in any layer of the contextualizing model. While representations of the same word in different contexts still have a greater cosine similarity than those of two different words, this self-similarity is much lower in upper layers. This suggests that upper layers of contextualizing models produce more context-specific representations, much like how upper layers of LSTMs produce more task-specific representations. In all layers of ELMo, BERT, and GPT-2, on average, less than 5% of the variance in a word's contextualized representations can be explained by a static embedding for that word, providing some justification for the success of contextualized representations.", "question": "How do they calculate a static embedding for each word?", "answer": "They use the first principal component of a word's contextualized representation in a given layer as its static embedding.", "answer_type": "free form answer"}, "target": "They use the first principal component of a word's contextualized representation in a given layer as its static embedding.", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings\\nABSTRACT: Replacing static word embeddings with contextualized word representations has yielded significant improvements on many NLP tasks. However, just how contextual are the contextualized representations produced by models such as ELMo and BERT? Are there infinitely many context-specific representations for each word, or are words essentially assigned one of a finite number of word-sense representations? For one, we find that the contextualized representations of all words are not isotropic in any layer of the contextualizing model. While representations of the same word in different contexts still have a greater cosine similarity than those of two different words, this self-similarity is much lower in upper layers. This suggests that upper layers of contextualizing models produce more context-specific representations, much like how upper layers of LSTMs produce more task-specific representations. In all layers of ELMo, BERT, and GPT-2, on average, less than 5% of the variance in a word's contextualized representations can be explained by a static embedding for that word, providing some justification for the success of contextualized representations.\\n\\nQ: How do they calculate a static embedding for each word?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["In the context of this study, a static embedding for each word is typically calculated by averaging the contextualized embeddings of that word across various contexts. This means that for each word, its occurrences in different sentences or contexts are considered, and the embeddings generated by the model (such as ELMo, BERT, or GPT-2) for these occurrences are averaged to produce a single, static representation. This averaged embedding serves as a baseline to compare against the more dynamic, context-specific embeddings produced by the model in different layers. The comparison helps to assess how much variance in the contextualized representations can be explained by a static embedding, highlighting the degree of contextualization achieved by the model."]], "filtered_resps": ["In the context of this study, a static embedding for each word is typically calculated by averaging the contextualized embeddings of that word across various contexts. This means that for each word, its occurrences in different sentences or contexts are considered, and the embeddings generated by the model (such as ELMo, BERT, or GPT-2) for these occurrences are averaged to produce a single, static representation. This averaged embedding serves as a baseline to compare against the more dynamic, context-specific embeddings produced by the model in different layers. The comparison helps to assess how much variance in the contextualized representations can be explained by a static embedding, highlighting the degree of contextualization achieved by the model."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "e3e9b9bc68cb6ccba05b874140470f430fcd87cff001eacbd9b391cab5a14ba6", "prompt_hash": "f5e3d02a09b63b5a9c6a28e8cfa0711ec4db0a131e51f05950fe103a28867639", "target_hash": "bc4b4f591abe17e44cbed49720ff3f09836b86d071b2aaac79cd5b0e461855fa", "f1_abstractive": 0.13675213675213677}
{"doc_id": 10, "doc": {"title": "Sensitive Data Detection and Classification in Spanish Clinical Text: Experiments with BERT", "abstract": "Massive digital data processing provides a wide range of opportunities and benefits, but at the cost of endangering personal data privacy. Anonymisation consists in removing or replacing sensitive information from data, enabling its exploitation for different purposes while preserving the privacy of individuals. Over the years, a lot of automatic anonymisation systems have been proposed; however, depending on the type of data, the target language or the availability of training documents, the task remains challenging still. The emergence of novel deep-learning models during the last two years has brought large improvements to the state of the art in the field of Natural Language Processing. These advancements have been most noticeably led by BERT, a model proposed by Google in 2018, and the shared language models pre-trained on millions of documents. In this paper, we use a BERT-based sequence labelling model to conduct a series of anonymisation experiments on several clinical datasets in Spanish. We also compare BERT to other algorithms. The experiments show that a simple BERT-based model with general-domain pre-training obtains highly competitive results without any domain specific feature engineering.", "question": "What is the performance of BERT on the task?", "answer": "F1 scores are:\nHUBES-PHI: Detection(0.965), Classification relaxed (0.95), Classification strict (0.937)\nMedoccan: Detection(0.972), Classification (0.967)", "answer_type": "free form answer"}, "target": "F1 scores are:\nHUBES-PHI: Detection(0.965), Classification relaxed (0.95), Classification strict (0.937)\nMedoccan: Detection(0.972), Classification (0.967)", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Sensitive Data Detection and Classification in Spanish Clinical Text: Experiments with BERT\\nABSTRACT: Massive digital data processing provides a wide range of opportunities and benefits, but at the cost of endangering personal data privacy. Anonymisation consists in removing or replacing sensitive information from data, enabling its exploitation for different purposes while preserving the privacy of individuals. Over the years, a lot of automatic anonymisation systems have been proposed; however, depending on the type of data, the target language or the availability of training documents, the task remains challenging still. The emergence of novel deep-learning models during the last two years has brought large improvements to the state of the art in the field of Natural Language Processing. These advancements have been most noticeably led by BERT, a model proposed by Google in 2018, and the shared language models pre-trained on millions of documents. In this paper, we use a BERT-based sequence labelling model to conduct a series of anonymisation experiments on several clinical datasets in Spanish. We also compare BERT to other algorithms. The experiments show that a simple BERT-based model with general-domain pre-training obtains highly competitive results without any domain specific feature engineering.\\n\\nQ: What is the performance of BERT on the task?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The paper suggests that the BERT-based sequence labeling model performs highly competitively on the task of sensitive data detection and classification in Spanish clinical text. The experiments indicate that even a simple BERT-based model with general-domain pre-training can achieve strong results without the need for domain-specific feature engineering. This implies that BERT is effective in handling the anonymization task in this context, although specific performance metrics such as accuracy, precision, recall, or F1-score are not provided in the abstract."]], "filtered_resps": ["The paper suggests that the BERT-based sequence labeling model performs highly competitively on the task of sensitive data detection and classification in Spanish clinical text. The experiments indicate that even a simple BERT-based model with general-domain pre-training can achieve strong results without the need for domain-specific feature engineering. This implies that BERT is effective in handling the anonymization task in this context, although specific performance metrics such as accuracy, precision, recall, or F1-score are not provided in the abstract."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "ca384d2631a530baef7d9c66402297b202a942a297f6841cdfda0cc4591a0877", "prompt_hash": "b5bc45182eac3522f841c5f4fdbddc9201f5b8e79dac74c8aa9a771c2530a98d", "target_hash": "784238f4675d7236205bf1467a567c314cc097db8bae758b0261d728eaa312bf", "f1_abstractive": 0.046511627906976744}
{"doc_id": 11, "doc": {"title": "Massively Multilingual Neural Grapheme-to-Phoneme Conversion", "abstract": "Grapheme-to-phoneme conversion (g2p) is necessary for text-to-speech and automatic speech recognition systems. Most g2p systems are monolingual: they require language-specific data or handcrafting of rules. Such systems are difficult to extend to low resource languages, for which data and handcrafted rules are not available. As an alternative, we present a neural sequence-to-sequence approach to g2p which is trained on spelling--pronunciation pairs in hundreds of languages. The system shares a single encoder and decoder across all languages, allowing it to utilize the intrinsic similarities between different writing systems. We show an 11% improvement in phoneme error rate over an approach based on adapting high-resource monolingual g2p models to low-resource languages. Our model is also much more compact relative to previous approaches.", "question": "how is model compactness measured?", "answer": "Using file size on disk", "answer_type": "free form answer"}, "target": "Using file size on disk", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Massively Multilingual Neural Grapheme-to-Phoneme Conversion\\nABSTRACT: Grapheme-to-phoneme conversion (g2p) is necessary for text-to-speech and automatic speech recognition systems. Most g2p systems are monolingual: they require language-specific data or handcrafting of rules. Such systems are difficult to extend to low resource languages, for which data and handcrafted rules are not available. As an alternative, we present a neural sequence-to-sequence approach to g2p which is trained on spelling--pronunciation pairs in hundreds of languages. The system shares a single encoder and decoder across all languages, allowing it to utilize the intrinsic similarities between different writing systems. We show an 11% improvement in phoneme error rate over an approach based on adapting high-resource monolingual g2p models to low-resource languages. Our model is also much more compact relative to previous approaches.\\n\\nQ: how is model compactness measured?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["Model compactness is typically measured in terms of the number of parameters the model has, the memory footprint it requires, and the computational resources needed for inference. A more compact model will have fewer parameters, require less memory, and be more efficient in terms of computation, making it faster and more suitable for deployment in resource-constrained environments. In the context of the paper, the compactness of the multilingual neural grapheme-to-phoneme conversion model likely refers to its ability to handle multiple languages with a single shared encoder and decoder, reducing the need for separate models for each language and thus minimizing the overall size and complexity of the system."]], "filtered_resps": ["Model compactness is typically measured in terms of the number of parameters the model has, the memory footprint it requires, and the computational resources needed for inference. A more compact model will have fewer parameters, require less memory, and be more efficient in terms of computation, making it faster and more suitable for deployment in resource-constrained environments. In the context of the paper, the compactness of the multilingual neural grapheme-to-phoneme conversion model likely refers to its ability to handle multiple languages with a single shared encoder and decoder, reducing the need for separate models for each language and thus minimizing the overall size and complexity of the system."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "53ae827f6a4e108f60ae2b30e6d3331609220b56a2f89ea702c42e4681f350a5", "prompt_hash": "be3761ce6a61b93a175659c4bbc32415cf16837f855acdf9fbdc0444952a395f", "target_hash": "a8ff74867dbb69faeb4a8c522ce061bf65fbf3ad62ac65b66c12524bee27830a", "f1_abstractive": 0.019999999999999997}
{"doc_id": 12, "doc": {"title": "Abstractive Summarization for Low Resource Data using Domain Transfer and Data Synthesis", "abstract": "Training abstractive summarization models typically requires large amounts of data, which can be a limitation for many domains. In this paper we explore using domain transfer and data synthesis to improve the performance of recent abstractive summarization methods when applied to small corpora of student reflections. First, we explored whether tuning state of the art model trained on newspaper data could boost performance on student reflection data. Evaluations demonstrated that summaries produced by the tuned model achieved higher ROUGE scores compared to model trained on just student reflection data or just newspaper data. The tuned model also achieved higher scores compared to extractive summarization baselines, and additionally was judged to produce more coherent and readable summaries in human evaluations. Second, we explored whether synthesizing summaries of student data could additionally boost performance. We proposed a template-based model to synthesize new data, which when incorporated into training further increased ROUGE scores. Finally, we showed that combining data synthesis with domain transfer achieved higher ROUGE scores compared to only using one of the two approaches.", "question": "Who were the human evaluators used?", "answer": "20 annotatos from author's institution", "answer_type": "free form answer"}, "target": "20 annotatos from author's institution", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Abstractive Summarization for Low Resource Data using Domain Transfer and Data Synthesis\\nABSTRACT: Training abstractive summarization models typically requires large amounts of data, which can be a limitation for many domains. In this paper we explore using domain transfer and data synthesis to improve the performance of recent abstractive summarization methods when applied to small corpora of student reflections. First, we explored whether tuning state of the art model trained on newspaper data could boost performance on student reflection data. Evaluations demonstrated that summaries produced by the tuned model achieved higher ROUGE scores compared to model trained on just student reflection data or just newspaper data. The tuned model also achieved higher scores compared to extractive summarization baselines, and additionally was judged to produce more coherent and readable summaries in human evaluations. Second, we explored whether synthesizing summaries of student data could additionally boost performance. We proposed a template-based model to synthesize new data, which when incorporated into training further increased ROUGE scores. Finally, we showed that combining data synthesis with domain transfer achieved higher ROUGE scores compared to only using one of the two approaches.\\n\\nQ: Who were the human evaluators used?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The abstract does not provide specific details about the human evaluators used in the study. It only mentions that human evaluations were conducted to judge the coherence and readability of the summaries produced by the tuned model. For more detailed information about the human evaluators, such as their background or expertise, you would need to refer to the full paper."]], "filtered_resps": ["The abstract does not provide specific details about the human evaluators used in the study. It only mentions that human evaluations were conducted to judge the coherence and readability of the summaries produced by the tuned model. For more detailed information about the human evaluators, such as their background or expertise, you would need to refer to the full paper."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "39650c8664ddccc3c2ca130d17abbc475929b96f4d3fd4b70b940eadc9003c19", "prompt_hash": "d5aefc1b89e388df111bc79bfa8b8fa777499ce59296129c4af9bdb274c8a472", "target_hash": "c31435fc6bdd9ebb658cf2032b6ab1ef60889257df23427ef137eed432edfee4", "f1_abstractive": 0}
{"doc_id": 13, "doc": {"title": "Stereotyping and Bias in the Flickr30K Dataset", "abstract": "An untested assumption behind the crowdsourced descriptions of the images in the Flickr30K dataset (Young et al., 2014) is that they\"focus only on the information that can be obtained from the image alone\"(Hodosh et al., 2013, p. 859). This paper presents some evidence against this assumption, and provides a list of biases and unwarranted inferences that can be found in the Flickr30K dataset. Finally, it considers methods to find examples of these, and discusses how we should deal with stereotype-driven descriptions in future applications.", "question": "Which methods are considered to find examples of biases and unwarranted inferences??", "answer": "Looking for adjectives marking the noun \"baby\" and also looking for most-common adjectives related to certain nouns using POS-tagging", "answer_type": "free form answer"}, "target": "Looking for adjectives marking the noun \"baby\" and also looking for most-common adjectives related to certain nouns using POS-tagging", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Stereotyping and Bias in the Flickr30K Dataset\\nABSTRACT: An untested assumption behind the crowdsourced descriptions of the images in the Flickr30K dataset (Young et al., 2014) is that they\\\"focus only on the information that can be obtained from the image alone\\\"(Hodosh et al., 2013, p. 859). This paper presents some evidence against this assumption, and provides a list of biases and unwarranted inferences that can be found in the Flickr30K dataset. Finally, it considers methods to find examples of these, and discusses how we should deal with stereotype-driven descriptions in future applications.\\n\\nQ: Which methods are considered to find examples of biases and unwarranted inferences??\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The paper likely considers a variety of methods to identify examples of biases and unwarranted inferences in the Flickr30K dataset. While the specific methods are not detailed in the abstract, common approaches in such research might include:"]], "filtered_resps": ["The paper likely considers a variety of methods to identify examples of biases and unwarranted inferences in the Flickr30K dataset. While the specific methods are not detailed in the abstract, common approaches in such research might include:"], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "35cbf5ad182a91d2e8c86d06031957d34b03d1392090b65c3684fbefe11c6d41", "prompt_hash": "ffa0570884bdf46aa5e599eec0371ad701868121f31c37a9cb24d8b4802d5f11", "target_hash": "ae7d746619ce1c2b734f5377443d3810413b39c37424c9558aa836bc3f297cef", "f1_abstractive": 0.08}
{"doc_id": 14, "doc": {"title": "Stereotyping and Bias in the Flickr30K Dataset", "abstract": "An untested assumption behind the crowdsourced descriptions of the images in the Flickr30K dataset (Young et al., 2014) is that they\"focus only on the information that can be obtained from the image alone\"(Hodosh et al., 2013, p. 859). This paper presents some evidence against this assumption, and provides a list of biases and unwarranted inferences that can be found in the Flickr30K dataset. Finally, it considers methods to find examples of these, and discusses how we should deal with stereotype-driven descriptions in future applications.", "question": "What biases are found in the dataset?", "answer": "Ethnic bias", "answer_type": "free form answer"}, "target": "Ethnic bias", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Stereotyping and Bias in the Flickr30K Dataset\\nABSTRACT: An untested assumption behind the crowdsourced descriptions of the images in the Flickr30K dataset (Young et al., 2014) is that they\\\"focus only on the information that can be obtained from the image alone\\\"(Hodosh et al., 2013, p. 859). This paper presents some evidence against this assumption, and provides a list of biases and unwarranted inferences that can be found in the Flickr30K dataset. Finally, it considers methods to find examples of these, and discusses how we should deal with stereotype-driven descriptions in future applications.\\n\\nQ: What biases are found in the dataset?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The paper identifies several types of biases and unwarranted inferences present in the Flickr30K dataset. These biases often stem from stereotypes and assumptions made by the individuals who provided the image descriptions. Some common biases include:"]], "filtered_resps": ["The paper identifies several types of biases and unwarranted inferences present in the Flickr30K dataset. These biases often stem from stereotypes and assumptions made by the individuals who provided the image descriptions. Some common biases include:"], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "098a2fa32749ed2ef95ee6ded95231564264f5e000a3748fbc373cc986b1cced", "prompt_hash": "8dbced7bf1fac21832173aded06a49930a6198dba328dd7238dae90c63a54789", "target_hash": "6f007904085e3ae499aebe1e1b5219c5ec02d8426eacb8f60714e054f25042e2", "f1_abstractive": 0}
{"doc_id": 15, "doc": {"title": "Improving Implicit Discourse Relation Classification by Modeling Inter-dependencies of Discourse Units in a Paragraph", "abstract": "We argue that semantic meanings of a sentence or clause can not be interpreted independently from the rest of a paragraph, or independently from all discourse relations and the overall paragraph-level discourse structure. With the goal of improving implicit discourse relation classification, we introduce a paragraph-level neural networks that model inter-dependencies between discourse units as well as discourse relation continuity and patterns, and predict a sequence of discourse relations in a paragraph. Experimental results show that our model outperforms the previous state-of-the-art systems on the benchmark corpus of PDTB.", "question": "What discourse relations does it work best/worst for?", "answer": "Best: Expansion (Exp). Worst: Comparison (Comp).", "answer_type": "free form answer"}, "target": "Best: Expansion (Exp). Worst: Comparison (Comp).", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Improving Implicit Discourse Relation Classification by Modeling Inter-dependencies of Discourse Units in a Paragraph\\nABSTRACT: We argue that semantic meanings of a sentence or clause can not be interpreted independently from the rest of a paragraph, or independently from all discourse relations and the overall paragraph-level discourse structure. With the goal of improving implicit discourse relation classification, we introduce a paragraph-level neural networks that model inter-dependencies between discourse units as well as discourse relation continuity and patterns, and predict a sequence of discourse relations in a paragraph. Experimental results show that our model outperforms the previous state-of-the-art systems on the benchmark corpus of PDTB.\\n\\nQ: What discourse relations does it work best/worst for?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The paper does not explicitly specify which discourse relations the model works best or worst for. However, it is common in discourse relation classification research to evaluate performance across various types of relations such as temporal, causal, contrastive, and additive. To determine the specific strengths and weaknesses of the model, one would typically need to look at detailed experimental results or supplementary materials that break down performance by relation type. If such information is not provided in the paper, further analysis or experiments would be necessary to identify which discourse relations the model handles most effectively or struggles with."]], "filtered_resps": ["The paper does not explicitly specify which discourse relations the model works best or worst for. However, it is common in discourse relation classification research to evaluate performance across various types of relations such as temporal, causal, contrastive, and additive. To determine the specific strengths and weaknesses of the model, one would typically need to look at detailed experimental results or supplementary materials that break down performance by relation type. If such information is not provided in the paper, further analysis or experiments would be necessary to identify which discourse relations the model handles most effectively or struggles with."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "76742f6d96f029d5951da95c5c1aa4f1dafa6e5ffb08230992449169aafce48d", "prompt_hash": "d56896aef4589bdf9a2ac83937a5f2c56fe10b44f25f380ef513419ffe02634a", "target_hash": "d342b6ffde4fa7d87ecfb191b3f53c1a66c307e0d6b2731586116cdc6e5a9f0f", "f1_abstractive": 0.04040404040404041}
{"doc_id": 16, "doc": {"title": "Hierarchical Transformers for Long Document Classification", "abstract": "BERT, which stands for Bidirectional Encoder Representations from Transformers, is a recently introduced language representation model based upon the transfer learning paradigm. We extend its fine-tuning procedure to address one of its major limitations - applicability to inputs longer than a few hundred words, such as transcripts of human call conversations. Our method is conceptually simple. We segment the input into smaller chunks and feed each of them into the base model. Then, we propagate each output through a single recurrent layer, or another transformer, followed by a softmax activation. We obtain the final classification decision after the last segment has been consumed. We show that both BERT extensions are quick to fine-tune and converge after as little as 1 epoch of training on a small, domain-specific data set. We successfully apply them in three different tasks involving customer call satisfaction prediction and topic classification, and obtain a significant improvement over the baseline models in two of them.", "question": "On top of BERT does the RNN layer work better or the transformer layer?", "answer": "The transformer layer", "answer_type": "free form answer"}, "target": "The transformer layer", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Hierarchical Transformers for Long Document Classification\\nABSTRACT: BERT, which stands for Bidirectional Encoder Representations from Transformers, is a recently introduced language representation model based upon the transfer learning paradigm. We extend its fine-tuning procedure to address one of its major limitations - applicability to inputs longer than a few hundred words, such as transcripts of human call conversations. Our method is conceptually simple. We segment the input into smaller chunks and feed each of them into the base model. Then, we propagate each output through a single recurrent layer, or another transformer, followed by a softmax activation. We obtain the final classification decision after the last segment has been consumed. We show that both BERT extensions are quick to fine-tune and converge after as little as 1 epoch of training on a small, domain-specific data set. We successfully apply them in three different tasks involving customer call satisfaction prediction and topic classification, and obtain a significant improvement over the baseline models in two of them.\\n\\nQ: On top of BERT does the RNN layer work better or the transformer layer?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The abstract does not explicitly state whether the RNN layer or the transformer layer works better on top of BERT for the tasks mentioned. It only mentions that both extensions (using a recurrent layer or another transformer) are quick to fine-tune and converge, and that they achieve significant improvements over baseline models in two of the tasks. To determine which layer works better, one would need to refer to the full paper for detailed experimental results and comparisons between the two approaches."]], "filtered_resps": ["The abstract does not explicitly state whether the RNN layer or the transformer layer works better on top of BERT for the tasks mentioned. It only mentions that both extensions (using a recurrent layer or another transformer) are quick to fine-tune and converge, and that they achieve significant improvements over baseline models in two of the tasks. To determine which layer works better, one would need to refer to the full paper for detailed experimental results and comparisons between the two approaches."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "00bf8f0853b689df86ad90c91a9ffff2bbc9dfecd2e7c853ff28f8d96e652ec2", "prompt_hash": "9e02cc010c3451449631981c29a7690212b19b102a23212b3d4cc20330c2d8b2", "target_hash": "9748aac7e629e04686bfbb4ba42d025161f5ee669191af16326369f7d2091c52", "f1_abstractive": 0.052631578947368425}
{"doc_id": 17, "doc": {"title": "Data Collection for Interactive Learning through the Dialog", "abstract": "This paper presents a dataset collected from natural dialogs which enables to test the ability of dialog systems to learn new facts from user utterances throughout the dialog. This interactive learning will help with one of the most prevailing problems of open domain dialog system, which is the sparsity of facts a dialog system can reason about. The proposed dataset, consisting of 1900 collected dialogs, allows simulation of an interactive gaining of denotations and questions explanations from users which can be used for the interactive learning.", "question": "How was this data collected?", "answer": "The crowdsourcing platform CrowdFlower was used to obtain natural dialog data that prompted the user to paraphrase, explain, and/or answer a question from a Simple questions BIBREF7 dataset. The CrowdFlower users were restricted to English-speaking countries to avoid dialogs  with poor English.", "answer_type": "free form answer"}, "target": "The crowdsourcing platform CrowdFlower was used to obtain natural dialog data that prompted the user to paraphrase, explain, and/or answer a question from a Simple questions BIBREF7 dataset. The CrowdFlower users were restricted to English-speaking countries to avoid dialogs  with poor English.", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Data Collection for Interactive Learning through the Dialog\\nABSTRACT: This paper presents a dataset collected from natural dialogs which enables to test the ability of dialog systems to learn new facts from user utterances throughout the dialog. This interactive learning will help with one of the most prevailing problems of open domain dialog system, which is the sparsity of facts a dialog system can reason about. The proposed dataset, consisting of 1900 collected dialogs, allows simulation of an interactive gaining of denotations and questions explanations from users which can be used for the interactive learning.\\n\\nQ: How was this data collected?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The data was collected from natural dialogs, likely involving interactions between human participants and possibly dialog systems. The process would have involved engaging users in conversations where they provided new facts, denotations, and explanations in response to questions. This setup allows the dialog system to simulate interactive learning by acquiring new information from user inputs throughout the dialog. The dataset comprises 1900 dialogs, which were specifically gathered to test and enhance the ability of dialog systems to learn and reason about new facts in an open domain context."]], "filtered_resps": ["The data was collected from natural dialogs, likely involving interactions between human participants and possibly dialog systems. The process would have involved engaging users in conversations where they provided new facts, denotations, and explanations in response to questions. This setup allows the dialog system to simulate interactive learning by acquiring new information from user inputs throughout the dialog. The dataset comprises 1900 dialogs, which were specifically gathered to test and enhance the ability of dialog systems to learn and reason about new facts in an open domain context."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "ae8512e33a9f2d7ae1415af22157b3f87b7ee15298072f38a66bf7cc184285e8", "prompt_hash": "ebdbf71d5fcdf3a6a9e7e51fab82fe24cc170beed1db7a5d81324b5b1bb0ea4d", "target_hash": "c066cdb7bdd229d4614098d7fc0307426c0eba68e3c7011503ace7e1e0912ec6", "f1_abstractive": 0.2542372881355932}
{"doc_id": 18, "doc": {"title": "Data Collection for Interactive Learning through the Dialog", "abstract": "This paper presents a dataset collected from natural dialogs which enables to test the ability of dialog systems to learn new facts from user utterances throughout the dialog. This interactive learning will help with one of the most prevailing problems of open domain dialog system, which is the sparsity of facts a dialog system can reason about. The proposed dataset, consisting of 1900 collected dialogs, allows simulation of an interactive gaining of denotations and questions explanations from users which can be used for the interactive learning.", "question": "What is the average length of dialog?", "answer": "4.49 turns", "answer_type": "free form answer"}, "target": "4.49 turns", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Data Collection for Interactive Learning through the Dialog\\nABSTRACT: This paper presents a dataset collected from natural dialogs which enables to test the ability of dialog systems to learn new facts from user utterances throughout the dialog. This interactive learning will help with one of the most prevailing problems of open domain dialog system, which is the sparsity of facts a dialog system can reason about. The proposed dataset, consisting of 1900 collected dialogs, allows simulation of an interactive gaining of denotations and questions explanations from users which can be used for the interactive learning.\\n\\nQ: What is the average length of dialog?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The abstract does not provide specific information about the average length of the dialogs in the dataset. To find the average length of dialog, you would need to refer to the full paper where the authors might have included detailed statistics and analysis of the dataset, including the average number of turns or utterances per dialog."]], "filtered_resps": ["The abstract does not provide specific information about the average length of the dialogs in the dataset. To find the average length of dialog, you would need to refer to the full paper where the authors might have included detailed statistics and analysis of the dataset, including the average number of turns or utterances per dialog."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "18d808a66ae237f6cc8d1617b284597e2c1fd89483f1330010540f75a980f2b4", "prompt_hash": "a7101a419424808b06f8c55f753401dba6566954fbd43f49edf9a624a9300142", "target_hash": "0844c1ab3f25abf69b7405ddec5bed2ad7c489d7545fecedbd6b5b325b4e3f9f", "f1_abstractive": 0.04081632653061224}
{"doc_id": 19, "doc": {"title": "Data Collection for Interactive Learning through the Dialog", "abstract": "This paper presents a dataset collected from natural dialogs which enables to test the ability of dialog systems to learn new facts from user utterances throughout the dialog. This interactive learning will help with one of the most prevailing problems of open domain dialog system, which is the sparsity of facts a dialog system can reason about. The proposed dataset, consisting of 1900 collected dialogs, allows simulation of an interactive gaining of denotations and questions explanations from users which can be used for the interactive learning.", "question": "What is the average length of dialog?", "answer": "4.5 turns per dialog (8533 turns / 1900 dialogs)", "answer_type": "free form answer"}, "target": "4.5 turns per dialog (8533 turns / 1900 dialogs)", "arguments": {"gen_args_0": {"arg_0": ["[{\"role\": \"user\", \"content\": \"TITLE: Data Collection for Interactive Learning through the Dialog\\nABSTRACT: This paper presents a dataset collected from natural dialogs which enables to test the ability of dialog systems to learn new facts from user utterances throughout the dialog. This interactive learning will help with one of the most prevailing problems of open domain dialog system, which is the sparsity of facts a dialog system can reason about. The proposed dataset, consisting of 1900 collected dialogs, allows simulation of an interactive gaining of denotations and questions explanations from users which can be used for the interactive learning.\\n\\nQ: What is the average length of dialog?\\n\\nA:\"}]"], "arg_1": {"until": ["\n"]}}}, "resps": [["The abstract does not provide specific information about the average length of the dialogs in the dataset. To find the average length of dialog, you would need to refer to the full paper where the authors might have included detailed statistics or analyses regarding the dialog lengths."]], "filtered_resps": ["The abstract does not provide specific information about the average length of the dialogs in the dataset. To find the average length of dialog, you would need to refer to the full paper where the authors might have included detailed statistics or analyses regarding the dialog lengths."], "filter": "none", "metrics": ["f1_abstractive"], "doc_hash": "17a3d8f15c560b3dac22c31db1ae1a4704e4843dccf8d805f8e7b921bf79e499", "prompt_hash": "a7101a419424808b06f8c55f753401dba6566954fbd43f49edf9a624a9300142", "target_hash": "e1bfdd9ad05128640827abd50096fdbf12646eb86026c0bb3d91c00290bf3330", "f1_abstractive": 0.0851063829787234}
